{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2678c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import random\n",
    "import array\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ba42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    for l in c:\n",
    "        d = dict(zip(header,l))\n",
    "        yield d['user_id'],d['recipe_id'],d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd228681",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f8dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most popular recipes\n",
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "validationSet = defaultdict(int)\n",
    "nums = 0\n",
    "totalRecipe = set()\n",
    "itemsPerUser = defaultdict(set)\n",
    "\n",
    "for user,recipe,_ in readCSV(\"assignment1/trainInteractions.csv.gz\"):\n",
    "    if nums >= 400000:\n",
    "        validationSet[(user,recipe)] = 1\n",
    "    else:\n",
    "        recipeCount[recipe] += 1\n",
    "        totalCooked += 1\n",
    "        totalRecipe.add(recipe)\n",
    "        itemsPerUser[user].add(recipe)\n",
    "        nums += 1\n",
    "        \n",
    "\n",
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d801b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalCooked/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4888e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_validationSet = defaultdict(int)\n",
    "for (u,r) in validationSet:\n",
    "    diff = list(totalRecipe - itemsPerUser[u])\n",
    "    uncook = random.choice(diff)\n",
    "    new_validationSet[(u,uncook)] = 0\n",
    "    new_validationSet[(u,r)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b72244",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_results = 0\n",
    "for (u,r) in new_validationSet:\n",
    "    if (r in return1 and new_validationSet[(u,r)] == 1) or (r not in return1 and new_validationSet[(u,r)] == 0):\n",
    "        right_results += 1\n",
    "    else:\n",
    "        right_results += 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a84d60b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance (accuracy) of the baseline model: 0.6647\n"
     ]
    }
   ],
   "source": [
    "Accuracy = right_results/len(new_validationSet)\n",
    "print('The performance (accuracy) of the baseline model: %.4f' %Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b7000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be200893",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eead37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c5e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = list(np.linspace(0,1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd3361fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_validationSet = defaultdict()\n",
    "for m in threshold_list:\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > totalCooked*m: break\n",
    "    right_results = 0\n",
    "    for (u,r) in new_validationSet:\n",
    "        if (r in return1 and new_validationSet[(u,r)] == 1) or (r not in return1 and new_validationSet[(u,r)] == 0):\n",
    "            right_results += 1\n",
    "        else:\n",
    "            right_results += 0\n",
    "    Accuracy = right_results/len(new_validationSet)\n",
    "    threshold_validationSet[m] = Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c38cc10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.59, 0.667431995758176)\n"
     ]
    }
   ],
   "source": [
    "for key,value in threshold_validationSet.items():\n",
    "    if(value == max(threshold_validationSet.values())):\n",
    "        print((key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e611e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3584a81a",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ef9a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2)) \n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed5f83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "nums1 = 0\n",
    "for user,recipe,_ in readCSV(\"assignment1/trainInteractions.csv.gz\"):\n",
    "    if nums1 < 400000:\n",
    "        usersPerItem[recipe].add(user)\n",
    "        nums1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93263dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_similarity(u,g):\n",
    "    similarities = []\n",
    "    training_recipes = itemsPerUser[u]\n",
    "    for recipe in training_recipes:\n",
    "        similarity = Jaccard(usersPerItem[g],usersPerItem[recipe])\n",
    "        similarities.append(similarity)\n",
    "    if len(similarities) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return max(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1059a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_results = 0\n",
    "threshold = 0.01\n",
    "for (u,r) in new_validationSet:\n",
    "    if (maximum_similarity(u,r) >= threshold and new_validationSet[(u,r)] == 1) or (maximum_similarity(u,r) < threshold and new_validationSet[(u,r)] == 0):\n",
    "        right_results += 1\n",
    "    else:\n",
    "        right_results += 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "274ff873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance (accuracy) of the baseline model: 0.5682\n"
     ]
    }
   ],
   "source": [
    "Accuracy = right_results/len(new_validationSet)\n",
    "print('The performance (accuracy) of the baseline model: %.4f' %Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd26a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f4af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab0e6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_result = defaultdict(float)\n",
    "for u,g in new_validationSet:\n",
    "    sim_result[(u,g)] = maximum_similarity(u,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02b35198",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_sim_validationSet = defaultdict()\n",
    "for k in list(np.linspace(0,1,101)):\n",
    "    sim_prediction = defaultdict(int)\n",
    "    for (m,n) in sim_result:\n",
    "        if sim_result[(m,n)] >= k:\n",
    "            sim_prediction[(m,n)] = 1\n",
    "        else:\n",
    "            sim_prediction[(m,n)] = 0\n",
    "    sim_right_result = 0\n",
    "    for (p,q) in sim_prediction:\n",
    "        if sim_prediction[(p,q)] == new_validationSet[(p,q)]:\n",
    "            sim_right_result += 1\n",
    "        else:\n",
    "            sim_right_result += 0\n",
    "    sim_Accuracy = sim_right_result/len(new_validationSet)\n",
    "    threshold_sim_validationSet[k] = sim_Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e298ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.01, 0.5682043278609802)\n"
     ]
    }
   ],
   "source": [
    "for key,value in threshold_sim_validationSet.items():\n",
    "    if(value == max(threshold_sim_validationSet.values())):\n",
    "        print((key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172c996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58cd7ce0",
   "metadata": {},
   "source": [
    "Question4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8d620bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_validationSet = new_validationSet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4f796de",
   "metadata": {},
   "outputs": [],
   "source": [
    "populatity_threshold = 0.59\n",
    "similarity_threshold = 0.01\n",
    "return_combine = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return_combine.add(i)\n",
    "  if count > totalCooked*populatity_threshold: break\n",
    "combine_right_results = 0\n",
    "for (u,r) in combine_validationSet:\n",
    "    if (r in return_combine and maximum_similarity(u,r) >= similarity_threshold and combine_validationSet[(u,r)] == 1) or ((r not in return_combine or maximum_similarity(u,r) < similarity_threshold) and combine_validationSet[(u,r)] == 0):\n",
    "        combine_right_results += 1\n",
    "    else:\n",
    "        combine_right_results += 0\n",
    "combine_accuracy = combine_right_results/len(combine_validationSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88466179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6528707344157988"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d114f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d774b72",
   "metadata": {},
   "source": [
    "Question5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18abfb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Made.txt\", 'w')\n",
    "for l in open(\"assignment1/stub_Made.txt\"):\n",
    "  if l.startswith(\"user_id\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,i = l.strip().split('-')\n",
    "  if (i in return_combine and maximum_similarity(u,i) >= similarity_threshold):\n",
    "    predictions.write(u + '-' + i + \",1\\n\")\n",
    "  else:\n",
    "    predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2050994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f147f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd392e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c22268d1",
   "metadata": {},
   "source": [
    "Question9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "b493833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV1(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    for l in c:\n",
    "        d = dict(zip(header,l))\n",
    "        yield d['user_id'],d['recipe_id'],d['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "7721afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "interactions = []\n",
    "\n",
    "for user,recipe, rating in readCSV1(\"assignment1/trainInteractions.csv.gz\"):\n",
    "    if not user in userIDs: userIDs[user] = len(userIDs)\n",
    "    if not recipe in itemIDs: itemIDs[recipe] = len(itemIDs)\n",
    "    interactions.append((user,recipe,int(rating)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "de337627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(interactions)\n",
    "len(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "dc53da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = int(len(interactions) * 0.9)\n",
    "nValidation = len(interactions) - nTrain\n",
    "interactionsTrain = interactions[:nTrain]\n",
    "interactionsValidation = interactions[nTrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "b3fba077",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "for u,i,r in interactionsTrain:\n",
    "    itemsPerUser[u].append(i)\n",
    "    usersPerItem[i].append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "0e577a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00000014', '50939497', 5),\n",
       " ('21919583', '94320955', 5),\n",
       " ('53994337', '39151782', 5),\n",
       " ('45601931', '02757863', 5),\n",
       " ('35541031', '77444570', 5),\n",
       " ('72697636', '21601840', 5),\n",
       " ('05472157', '63771765', 4),\n",
       " ('49044514', '38256576', 5),\n",
       " ('59205393', '65374177', 5),\n",
       " ('64368882', '27610964', 5)]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactionsTrain[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "a78a9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = sum([r for _,_,r in interactionsTrain]) / len(interactionsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "f7a518ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "b7f48679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorModel(tf.keras.Model):\n",
    "    def __init__(self, mu, K, lamb):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i]\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaI**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "c476cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLFM = LatentFactorModel(mu, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "1d368e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStep(model, interactions):\n",
    "    Nsamples = 50000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactions)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "f3126555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 3.3557003\n",
      "iteration 20, objective = 1.2718706\n",
      "iteration 30, objective = 0.5391916\n",
      "iteration 40, objective = 0.46692204\n",
      "iteration 50, objective = 0.4973867\n",
      "iteration 60, objective = 0.45403153\n",
      "iteration 70, objective = 0.45464355\n",
      "iteration 80, objective = 0.46259156\n",
      "iteration 90, objective = 0.4431317\n",
      "iteration 100, objective = 0.45313326\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    obj = trainingStep(modelLFM, interactionsTrain)\n",
    "    if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "8b279b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "for k in range(len(interactionsValidation)):\n",
    "    error.append((modelLFM.predict(userIDs[interactionsValidation[k][0]], itemIDs[interactionsValidation[k][1]]).numpy() - interactionsValidation[k][2]) **2)       \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "76169fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8830935668470781"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(error)/len(interactionsValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae358dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ffe112a",
   "metadata": {},
   "source": [
    "Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "db4a5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_coefficient = tf.get_static_value(modelLFM.trainable_variables)[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "36448bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_coefficient = tf.get_static_value(modelLFM.trainable_variables)[2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "a67b73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contant_coefficient = tf.get_static_value(modelLFM.trainable_variables)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "33727f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.39616837e-04,  1.07845335e-05, -2.45239917e-05, ...,\n",
       "       -3.58505313e-05,  1.66078262e-05, -2.45104839e-05], dtype=float32)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "6053b68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.0576572e-05, -6.4843814e-05, -2.7597243e-05, ...,\n",
       "        3.8888909e-05,  2.0743835e-05,  2.2903696e-05], dtype=float32)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "8c3dfec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.583514"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contant_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "1d169d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([32]),)\n",
      "(array([1079]),)\n",
      "(array([1197]),)\n",
      "(array([625]),)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(user_coefficient == max(user_coefficient)))\n",
    "print(np.where(user_coefficient == min(user_coefficient)))\n",
    "print(np.where(recipe_coefficient == max(recipe_coefficient)))\n",
    "print(np.where(recipe_coefficient == min(recipe_coefficient)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "4c9c6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "for m,n in userIDs.items():\n",
    "    users.append(m)\n",
    "recipes = []\n",
    "for m,n in itemIDs.items():\n",
    "    recipes.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "c208e171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id 32445558 has largest β, which is 0.00180891\n",
      "user_id 47394745 has smallest β, which is -0.00075586\n",
      "recipe_id 78039087 has largest β, which is 0.00021212\n",
      "recipe_id 48134500 has smallest β, which is -0.00038894\n"
     ]
    }
   ],
   "source": [
    "print('user_id %s has largest β, which is %.8f' % (users[32],max(user_coefficient)))\n",
    "print('user_id %s has smallest β, which is %.8f' % (users[1079],min(user_coefficient)))\n",
    "print('recipe_id %s has largest β, which is %.8f' % (recipes [1197],max(recipe_coefficient)))\n",
    "print('recipe_id %s has smallest β, which is %.8f' % (recipes[625],min(recipe_coefficient)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421aa8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec83d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fac115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd6433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134233f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29e654ba",
   "metadata": {},
   "source": [
    "Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "f728f0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000 has finished\n",
      "0.100 has finished\n",
      "0.200 has finished\n",
      "0.300 has finished\n",
      "0.400 has finished\n",
      "0.500 has finished\n",
      "0.600 has finished\n",
      "0.700 has finished\n",
      "0.800 has finished\n",
      "0.900 has finished\n",
      "1.000 has finished\n",
      "1.100 has finished\n",
      "1.200 has finished\n",
      "1.300 has finished\n",
      "1.400 has finished\n",
      "1.500 has finished\n"
     ]
    }
   ],
   "source": [
    "lambda_list = list(np.linspace(0,1.5,16))\n",
    "parameter_MSE = defaultdict()\n",
    "\n",
    "for parameter in lambda_list:\n",
    "    modelLFM = LatentFactorModel(mu, 3, parameter)\n",
    "    for i in range(100):\n",
    "        obj = trainingStep(modelLFM, interactionsTrain)\n",
    "    error = []\n",
    "    for k in range(len(interactionsValidation)):\n",
    "        error.append((modelLFM.predict(userIDs[interactionsValidation[k][0]], itemIDs[interactionsValidation[k][1]]).numpy() - interactionsValidation[k][2]) **2)       \n",
    "        MSE = sum(error)/len(interactionsValidation)\n",
    "    parameter_MSE[parameter] = MSE\n",
    "    print('%.3f has finished' %parameter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "e469f9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {0.0: 1.0891953850526088,\n",
       "             0.1: 0.8826298649206996,\n",
       "             0.2: 0.8828579107313518,\n",
       "             0.30000000000000004: 0.8829745396646076,\n",
       "             0.4: 0.8831993624126229,\n",
       "             0.5: 0.8830469733862273,\n",
       "             0.6000000000000001: 0.8831833483889044,\n",
       "             0.7000000000000001: 0.8833700493189064,\n",
       "             0.8: 0.8831520837649725,\n",
       "             0.9: 0.8830983293819503,\n",
       "             1.0: 0.8830958948372504,\n",
       "             1.1: 0.8832427753585286,\n",
       "             1.2000000000000002: 0.8831522849164533,\n",
       "             1.3: 0.8830889894473811,\n",
       "             1.4000000000000001: 0.8832850257509783,\n",
       "             1.5: 0.8831148050989813})"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2656340",
   "metadata": {},
   "source": [
    "It seems like when λ = 0.1, the model has the lowest MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "f8964a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 31.607483\n",
      "iteration 20, objective = 143.04257\n",
      "iteration 30, objective = 74.68475\n",
      "iteration 40, objective = 17.782276\n",
      "iteration 50, objective = 2.444204\n",
      "iteration 60, objective = 1.0546409\n",
      "iteration 70, objective = 1.1220791\n",
      "iteration 80, objective = 0.8010258\n",
      "iteration 90, objective = 0.53845966\n",
      "iteration 100, objective = 0.45863461\n"
     ]
    }
   ],
   "source": [
    "best_modelLFM = LatentFactorModel(mu, 3, 0.1)\n",
    "for i in range(100):\n",
    "    obj = trainingStep(best_modelLFM, interactionsTrain)\n",
    "    if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "c4fde072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8826100637566288"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = []\n",
    "for k in range(len(interactionsValidation)):\n",
    "    error.append((best_modelLFM.predict(userIDs[interactionsValidation[k][0]], itemIDs[interactionsValidation[k][1]]).numpy() - interactionsValidation[k][2]) **2)  \n",
    "MSE_new = sum(error)/len(interactionsValidation)\n",
    "MSE_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "5ef97f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "contant_coefficient = tf.get_static_value(best_modelLFM.trainable_variables)[0].numpy()\n",
    "predictions = open(\"predictions_Rated.txt\", 'w')\n",
    "for l in open(\"assignment1/stub_Rated.txt\"):\n",
    "  if l.startswith(\"user_id\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,i = l.strip().split('-')\n",
    "  if u in userIDs and i in itemIDs:\n",
    "    predictions.write(u + '-' + i + ',' + str(best_modelLFM.predict(userIDs[u], itemIDs[i]).numpy()) + '\\n')\n",
    "  else:\n",
    "    predictions.write(u + '-' + i + ',' + str(contant_coefficient) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80a7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e17706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
